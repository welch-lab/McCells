{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached ontology from /Users/jzhao/dev/Welch-lab/McCell/data/processed/ontology.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The \"stable\" release is currently 2025-01-30. Specify 'census_version=\"2025-01-30\"' in future calls to open_soma() to ensure data consistency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontology loaded successfully.\n",
      "Fetching descendants of CL:0000988...\n",
      "Connecting to CellXGene Census...\n",
      "Reading cell metadata to filter cell types...\n",
      "Found 160 cell types with > 5000 cells.\n",
      "Querying for final cell metadata...\n",
      "Finished loading and filtering cell metadata.\n",
      "141 cell types in the dataset 41 leaf types, 100 internal types\n",
      "Loaded 141 cell types.\n",
      "Cell children mask shape: torch.Size([141, 141])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from src.utils.ontology_utils import load_ontology\n",
    "from src.data_pipeline.data_loader import load_filtered_cell_metadata\n",
    "from src.data_pipeline.preprocess_ontology import preprocess_data_ontology\n",
    "from src.utils.paths import PROJECT_ROOT\n",
    "from src.utils.ontology_utils import get_sub_DAG\n",
    "\n",
    "# 1. Load the cached ontology object\n",
    "cl = load_ontology()\n",
    "\n",
    "# Define the root of the ontology subgraph to be processed\n",
    "root_cl_id = 'CL:0000988'  # hematopoietic cell\n",
    "\n",
    "# 2. Load filtered cell metadata from CellXGene Census\n",
    "# This step can take a few minutes\n",
    "cell_obs_metadata = load_filtered_cell_metadata(cl, root_cl_id=root_cl_id)\n",
    "\n",
    "# 3. Preprocess the ontology and cell data\n",
    "target_column = 'cell_type_ontology_term_id'\n",
    "\n",
    "mapping_dict, leaf_values, internal_values, ontology_df, cell_children_mask = preprocess_data_ontology(\n",
    "        cl, cell_obs_metadata, target_column,\n",
    "        upper_limit=root_cl_id,\n",
    "        cl_only=True, include_leafs=False\n",
    "    )\n",
    "\n",
    "reverse_mapping_dict = {v: k for k, v in mapping_dict.items()}\n",
    "\n",
    "print(f'Loaded {len(mapping_dict)} cell types.')\n",
    "print(\"Cell children mask shape:\", cell_children_mask.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cellxgene_census\n",
    "import cellxgene_census.experimental.ml as census_ml\n",
    "import tiledbsoma as soma\n",
    "\n",
    "all_cell_values = list(mapping_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and filtering gene list from hpc_workaround/data/mart_export.txt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The \"stable\" release is currently 2025-01-30. Specify 'census_version=\"2025-01-30\"' in future calls to open_soma() to ensure data consistency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying 141 cell types and 500 protein-coding genes.\n",
      "Querying 141 cell types and 500 genes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y8/l94zj4_d0798ps_qdcdsxfw40000gn/T/ipykernel_14915/2991660118.py:18: FutureWarning: cellxgene_census.experimental.ml.pytorch API will be removed in an upcoming release; upgrade to TileDB-SOMA-ML: https://github.com/single-cell-data/TileDB-SOMA-ML\n",
      "  experiment_datapipe = census_ml.pytorch.ExperimentDataPipe(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataLoaders are ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y8/l94zj4_d0798ps_qdcdsxfw40000gn/T/ipykernel_14915/2991660118.py:31: FutureWarning: cellxgene_census.experimental.ml.pytorch API will be removed in an upcoming release; upgrade to TileDB-SOMA-ML: https://github.com/single-cell-data/TileDB-SOMA-ML\n",
      "  train_dataloader = census_ml.experiment_dataloader(train_datapipe)\n",
      "/var/folders/y8/l94zj4_d0798ps_qdcdsxfw40000gn/T/ipykernel_14915/2991660118.py:32: FutureWarning: cellxgene_census.experimental.ml.pytorch API will be removed in an upcoming release; upgrade to TileDB-SOMA-ML: https://github.com/single-cell-data/TileDB-SOMA-ML\n",
      "  val_dataloader = census_ml.experiment_dataloader(val_datapipe)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the gene list from the file you found and filter for protein-coding genes.\n",
    "print(\"Loading and filtering gene list from hpc_workaround/data/mart_export.txt...\")\n",
    "biomart = pd.read_csv(\"/Users/jzhao/dev/Welch-lab/McCell/hpc_workaround/data/mart_export.txt\")\n",
    "coding_only = biomart[biomart['Gene type'] == 'protein_coding']\n",
    "gene_list = coding_only['Gene stable ID'].tolist()[:500]  # Limit to first 500 genes for speed\n",
    "\n",
    "# Create filters for the data query, including the assay and primary data filters.\n",
    "var_value_filter = f\"feature_id in {gene_list}\"\n",
    "obs_value_filter = f'''assay == \"10x 3' v3\" and is_primary_data == True and cell_type_ontology_term_id in {all_cell_values}'''\n",
    "\n",
    "print(f\"Querying {len(all_cell_values)} cell types and {len(gene_list)} protein-coding genes.\")\n",
    "\n",
    "with cellxgene_census.open_soma() as census:\n",
    "    \n",
    "\n",
    "    print(f\"Querying {len(all_cell_values)} cell types and {len(gene_list)} genes.\")\n",
    "\n",
    "    experiment_datapipe = census_ml.pytorch.ExperimentDataPipe(\n",
    "        census[\"census_data\"][\"homo_sapiens\"],\n",
    "        measurement_name=\"RNA\",\n",
    "        X_name=\"raw\",\n",
    "        obs_query=soma.AxisQuery(value_filter=obs_value_filter),\n",
    "        var_query=soma.AxisQuery(value_filter=var_value_filter),\n",
    "        obs_column_names=[\"cell_type_ontology_term_id\"],\n",
    "        batch_size=256,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # Create the train/validation split\n",
    "    train_datapipe, val_datapipe = experiment_datapipe.random_split(weights={\"train\": 0.8, \"val\": 0.2}, seed=42)\n",
    "    train_dataloader = census_ml.experiment_dataloader(train_datapipe)\n",
    "    val_dataloader = census_ml.experiment_dataloader(val_datapipe)\n",
    "\n",
    "print(\"\\nDataLoaders are ready.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verifying a single batch of data ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Verifying a single batch of data ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Take one batch from the train_dataloader\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m X_batch, y_batch_meta = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape of X_batch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_batch.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape of y_batch_meta: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_batch_meta.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Welch-lab/McCell/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Welch-lab/McCell/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Welch-lab/McCell/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:42\u001b[39m, in \u001b[36m_IterableDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     40\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     data = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.collate_fn(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Welch-lab/McCell/.venv/lib/python3.11/site-packages/torch/utils/data/datapipes/_hook_iterator.py:172\u001b[39m, in \u001b[36mhook_iterator.<locals>.IteratorDecorator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    170\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_next()\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Welch-lab/McCell/.venv/lib/python3.11/site-packages/torch/utils/data/datapipes/_hook_iterator.py:160\u001b[39m, in \u001b[36mhook_iterator.<locals>.IteratorDecorator._get_next\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return next with logic related to iterator validity, profiler, and incrementation of samples yielded.\"\"\"\u001b[39;00m\n\u001b[32m    159\u001b[39m _check_iterator_valid(\u001b[38;5;28mself\u001b[39m.datapipe, \u001b[38;5;28mself\u001b[39m.iterator_id)\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m result = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.self_and_has_next_method:\n\u001b[32m    162\u001b[39m     \u001b[38;5;28mself\u001b[39m.datapipe._number_of_samples_yielded += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Welch-lab/McCell/.venv/lib/python3.11/site-packages/torch/utils/data/datapipes/_hook_iterator.py:251\u001b[39m, in \u001b[36mhook_iterator.<locals>.wrap_next\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    249\u001b[39m         result = next_func(*args, **kwargs)\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     result = \u001b[43mnext_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m datapipe._number_of_samples_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Welch-lab/McCell/.venv/lib/python3.11/site-packages/torch/utils/data/datapipes/datapipe.py:411\u001b[39m, in \u001b[36m_IterDataPipeSerializationWrapper.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> _T_co:  \u001b[38;5;66;03m# type: ignore[type-var]\u001b[39;00m\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._datapipe_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_datapipe_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Welch-lab/McCell/.venv/lib/python3.11/site-packages/torch/utils/data/datapipes/_hook_iterator.py:204\u001b[39m, in \u001b[36mhook_iterator.<locals>.wrap_generator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m         response = gen.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     response = \u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    207\u001b[39m     datapipe._number_of_samples_yielded += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Welch-lab/McCell/.venv/lib/python3.11/site-packages/torchdata/datapipes/iter/util/randomsplitter.py:185\u001b[39m, in \u001b[36mSplitterIterator.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    184\u001b[39m     \u001b[38;5;28mself\u001b[39m.main_datapipe.reset()\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmain_datapipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43msource_datapipe\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmain_datapipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Welch-lab/McCell/.venv/lib/python3.11/site-packages/torch/utils/data/datapipes/_hook_iterator.py:204\u001b[39m, in \u001b[36mhook_iterator.<locals>.wrap_generator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m         response = gen.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     response = \u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    207\u001b[39m     datapipe._number_of_samples_yielded += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Welch-lab/McCell/.venv/lib/python3.11/site-packages/cellxgene_census/experimental/ml/pytorch.py:693\u001b[39m, in \u001b[36mExperimentDataPipe.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _open_experiment(\u001b[38;5;28mself\u001b[39m.exp_uri, \u001b[38;5;28mself\u001b[39m.aws_region) \u001b[38;5;28;01mas\u001b[39;00m exp:\n\u001b[32m    678\u001b[39m     obs_and_x_iter = _ObsAndXIterator(\n\u001b[32m    679\u001b[39m         obs=exp.obs,\n\u001b[32m    680\u001b[39m         X=exp.ms[\u001b[38;5;28mself\u001b[39m.measurement_name].X[\u001b[38;5;28mself\u001b[39m.layer_name],\n\u001b[32m   (...)\u001b[39m\u001b[32m    690\u001b[39m         shuffle_chunk_count=\u001b[38;5;28mself\u001b[39m._shuffle_chunk_count,\n\u001b[32m    691\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m693\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m obs_and_x_iter\n\u001b[32m    695\u001b[39m     \u001b[38;5;28mself\u001b[39m.max_process_mem_usage_bytes = obs_and_x_iter.max_process_mem_usage_bytes\n\u001b[32m    696\u001b[39m     pytorch_logger.debug(\n\u001b[32m    697\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmax process memory usage=\u001b[39m\u001b[33m\"\u001b[39m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.max_process_mem_usage_bytes\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m(\u001b[32m1024\u001b[39m\u001b[38;5;250m \u001b[39m**\u001b[38;5;250m \u001b[39m\u001b[32m3\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m GiB\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    698\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Welch-lab/McCell/.venv/lib/python3.11/site-packages/cellxgene_census/experimental/ml/pytorch.py:322\u001b[39m, in \u001b[36m_ObsAndXIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m n_obs < \u001b[38;5;28mself\u001b[39m.batch_size:\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m         obs_partial, X_partial = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_partial_torch_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_obs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m         n_obs += \u001b[38;5;28mlen\u001b[39m(obs_partial)\n\u001b[32m    324\u001b[39m         obss.append(obs_partial)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Welch-lab/McCell/.venv/lib/python3.11/site-packages/cellxgene_census/experimental/ml/pytorch.py:378\u001b[39m, in \u001b[36m_ObsAndXIterator._read_partial_torch_batch\u001b[39m\u001b[34m(self, batch_size)\u001b[39m\n\u001b[32m    375\u001b[39m pre_gc, _, gc_elapsed = run_gc()\n\u001b[32m    376\u001b[39m \u001b[38;5;28mself\u001b[39m.max_process_mem_usage_bytes = \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m.max_process_mem_usage_bytes, pre_gc[\u001b[32m0\u001b[39m].uss)\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m \u001b[38;5;28mself\u001b[39m.soma_chunk: _SOMAChunk = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msoma_chunk_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28mself\u001b[39m.stats += \u001b[38;5;28mself\u001b[39m.soma_chunk.stats\n\u001b[32m    380\u001b[39m \u001b[38;5;28mself\u001b[39m.gc_elapsed += gc_elapsed\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Welch-lab/McCell/.venv/lib/python3.11/site-packages/cellxgene_census/experimental/util/_eager_iter.py:34\u001b[39m, in \u001b[36m_EagerIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._future\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_future\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28mself\u001b[39m._begin_next()\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.13-macos-aarch64-none/lib/python3.11/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.13-macos-aarch64-none/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- Verify a single batch of streamed data ---\n",
    "print(\"\\n--- Verifying a single batch of data ---\")\n",
    "\n",
    "# Take one batch from the train_dataloader\n",
    "X_batch, y_batch_meta = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"Shape of X_batch: {X_batch.shape}\")\n",
    "print(f\"Shape of y_batch_meta: {y_batch_meta.shape}\")\n",
    "\n",
    "# Let's look at the first 5 cells\n",
    "num_to_show = 5\n",
    "X_sample = X_batch[:num_to_show]\n",
    "y_sample_meta = y_batch_meta[:num_to_show]\n",
    "\n",
    "# Map ontology terms (CL IDs) to integer labels\n",
    "y_sample = torch.tensor(\n",
    "    [mapping_dict[term] for term in y_sample_meta[:, 0]],\n",
    "    dtype=torch.long\n",
    ")\n",
    "\n",
    "# Reverse dictionary for displaying CL term back from integer index\n",
    "reverse_mapping_dict = {v: k for k, v in mapping_dict.items()}\n",
    "\n",
    "print(\"\\nExample cells (first 5):\")\n",
    "print(\"Cell # | y_meta (CL term)           | mapped label idx | X nonzero entries\")\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "for i in range(num_to_show):\n",
    "    cl_id = y_sample_meta[i, 0]\n",
    "    label_idx = y_sample[i].item()\n",
    "    nnz = int((X_sample[i] != 0).sum())  # number of expressed genes in sparse row\n",
    "    print(f\"{i:<6} | {cl_id:<25} | {label_idx:<16} | {nnz}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Starting a short training run for 2 epochs (50 batches each)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _EagerIterator.__del__ at 0x30bce5d00>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jzhao/dev/Welch-lab/McCell/.venv/lib/python3.11/site-packages/cellxgene_census/experimental/util/_eager_iter.py\", line 50, in __del__\n",
      "    self._cleanup()\n",
      "  File \"/Users/jzhao/dev/Welch-lab/McCell/.venv/lib/python3.11/site-packages/cellxgene_census/experimental/util/_eager_iter.py\", line 44, in _cleanup\n",
      "    self._pool.shutdown()\n",
      "  File \"/Users/jzhao/.local/share/uv/python/cpython-3.11.13-macos-aarch64-none/lib/python3.11/concurrent/futures/thread.py\", line 235, in shutdown\n",
      "    t.join()\n",
      "  File \"/Users/jzhao/.local/share/uv/python/cpython-3.11.13-macos-aarch64-none/lib/python3.11/threading.py\", line 1119, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/Users/jzhao/.local/share/uv/python/cpython-3.11.13-macos-aarch64-none/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "from src.train.model import SimpleNN\n",
    "from src.train.loss import MarginalizationLoss\n",
    "\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Setup ---\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "input_dim = experiment_datapipe.shape[1]\n",
    "output_dim = len(leaf_values)\n",
    "\n",
    "model = SimpleNN(input_dim=input_dim, output_dim=output_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Instantiate the loss function.\n",
    "# It now correctly creates the leaf_indices set internally.\n",
    "loss_fn = MarginalizationLoss(\n",
    "    ontology_df=ontology_df,\n",
    "    leaf_values=leaf_values,\n",
    "    mapping_dict=mapping_dict,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# --- 2. Training Loop (Short Run) ---\n",
    "num_epochs = 1\n",
    "batches_per_epoch = 5  # Limit the run to 500 batches per epoch for speed\n",
    "batch_loss_history = []\n",
    "\n",
    "print(f\"\\nStarting a short training run for {num_epochs} epochs ({batches_per_epoch} batches each)...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        if i >= batches_per_epoch:\n",
    "            break\n",
    "        \n",
    "        X_batch, y_batch_meta = batch\n",
    "        X_batch = X_batch.float().to(device)\n",
    "        y_batch = torch.tensor([mapping_dict[term] for term in y_batch_meta[:, 0]], device=device, dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        total_loss, _, _ = loss_fn(outputs, y_batch)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record loss for plotting\n",
    "        batch_loss_history.append(total_loss.item())\n",
    "\n",
    "        running_loss += total_loss.item()\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# --- 3. Plotting Loss ---\n",
    "print(\"\\nPlotting training loss...\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(batch_loss_history, label='Total Loss per Batch')\n",
    "plt.xlabel(\"Batch Number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.92.136.210\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "print(socket.gethostbyname(\"cellxgene-census-public-us-west-2.s3.us-west-2.amazonaws.com\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "McCell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
